{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec249343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fe233e70-0b8c-4705-abcf-b0ffe9bf74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Applies the sigmoid function.\"\"\"\n",
    "        return np.where(x >= 0, \n",
    "                        1 / (1 + np.exp(-x)), \n",
    "                        np.exp(x) / (1 + np.exp(x)))\n",
    "    \n",
    "    def negative_log_likelihood(self, X, Y):\n",
    "        \"\"\"Computes the negative log-likelihood.\"\"\"\n",
    "        logits = X @ self.params\n",
    "        return -np.sum(Y * np.log(self.sigmoid(logits)) + (1 - Y) * np.log(1 - self.sigmoid(logits)))\n",
    "\n",
    "    def gradient(self, X, Y):\n",
    "        \"\"\"Computes the gradient of the negative log-likelihood function.\"\"\"\n",
    "        logits = X @ self.params\n",
    "        errors = self.sigmoid(logits) - Y\n",
    "        return X.T @ errors\n",
    "\n",
    "    def default_learning_rate(self, X):\n",
    "        \"\"\"Computes the default learning rate using Hessian of the negative log-likelihood function.\"\"\"\n",
    "        logits = X @ self.params\n",
    "        hessian_approx = np.sum(self.sigmoid(logits) * (1 - self.sigmoid(logits)))\n",
    "        if hessian_approx > 1e-10:\n",
    "            return 1 / hessian_approx\n",
    "        else:\n",
    "            return 1e-2\n",
    "\n",
    "    def fit(self, X_train, Y_train, learning_rate=None, max_iter=10000, verbose=False):\n",
    "        \"\"\"Fits the model using gradient descent with specified learning rate or one calculated using the Hessian.\"\"\"\n",
    "        X = X_train.values\n",
    "        Y = Y_train.to_numpy()\n",
    "        n_features = X.shape[1]\n",
    "        self.params = np.zeros(n_features)  # Initialize parameters\n",
    "\n",
    "        if learning_rate is None:\n",
    "            learning_rate = self.default_learning_rate(X)\n",
    "        \n",
    "        for iteration in range(max_iter):\n",
    "            grad = self.gradient(X, Y)\n",
    "            self.params -= learning_rate * grad  # Gradient descent update\n",
    "\n",
    "            # Print the loss every 100 iterations if verbosity mode is active\n",
    "            if verbose:\n",
    "                if iteration % 100 == 0:\n",
    "                    loss = self.negative_log_likelihood(X, Y)\n",
    "                    print(f\"Iteration {i}: Loss = {loss:.4f}\")\n",
    "        if verbose:\n",
    "            print(f\"Final iteration: Loss = {self.negative_log_likelihood(X, Y):.4f}\")\n",
    "\n",
    "    def predict_probs(self, X_train):\n",
    "        \"\"\"Predicts probabilities of labels for input data.\"\"\"\n",
    "        return self.sigmoid(X_train.values @ self.params)\n",
    "\n",
    "    def predict(self, X_train, threshold=0.5):\n",
    "        \"\"\"Predicts class labels for input data with a given threshhold.\"\"\"\n",
    "        return (self.predict_probs(X_train) >= threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d65c4845-0f73-40c1-8816-5a72e00f3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(logistic_regression_model, n_samples=1000, n_columns=2, true_params=None, \n",
    "         learning_rate=None, max_iter=1000, random_seed=None, verbose=False):\n",
    "    \"\"\"Function testing the accuracy of the logistic regression class\"\"\"\n",
    "    random_state = np.random.default_rng(random_seed)\n",
    "    if verbose:\n",
    "        print(f\"Shape of training data: ({n_samples}, {n_columns})\")\n",
    "    X_train = pd.DataFrame(random_state.normal(loc=0, scale=5, size=(n_samples, n_columns)))\n",
    "    X_train[\"constant\"] = 1\n",
    "    if true_params is None:\n",
    "        true_params = random_state.normal(loc=0, scale=5, size=n_columns+1)\n",
    "    model = logistic_regression_model()\n",
    "    Y_train = pd.Series((random_state.uniform(size=n_samples) < model.sigmoid(X_train.values @ true_params)).astype(int))\n",
    "    model.fit(X_train, Y_train, learning_rate=learning_rate, max_iter=max_iter)\n",
    "    if verbose:\n",
    "        print(f\"Correct parameters: {true_params}, Fitted parameters: {model.params}\")\n",
    "        \n",
    "    predictions = model.predict(X_train)\n",
    "    accuracy = np.mean(predictions == Y_train)\n",
    "    if verbose:\n",
    "        print(f\"Model's accuracy:{accuracy}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a62f5b19-b5e0-4f06-ac44-045dfb4096b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (1000, 2)\n",
      "Correct parameters: [5, -2, 3], Fitted parameters: [ 4.41870322 -1.7140476   2.82231737]\n",
      "Model's accuracy:0.972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.972)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(LogisticRegression, n_samples=1000, n_columns=2, max_iter=10000, true_params=[5, -2, 3], random_seed=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "253cbbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9879059179357647\n"
     ]
    }
   ],
   "source": [
    "test_numer = 100\n",
    "accuracies = []\n",
    "for i in range(test_numer):\n",
    "    random_state = np.random.default_rng(i)\n",
    "    n_samples = random_state.integers(100, 1000)\n",
    "    n_columns= random_state.integers(1, 10)\n",
    "    accuracies.append(test(LogisticRegression, n_samples=n_samples, n_columns=n_columns, max_iter=1000, random_seed=i, verbose=False))\n",
    "print(np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d10a6b-d66e-4dab-a52d-4442b6e79210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
